#!/bin/bash

# Cd into our working directory in case we're not into it already
cd "$(dirname "$0")";

echo "----------------------------------------------------------------------------------------------"
echo "gfs: Starting processing of GFS model data - `date`"
echo "----------------------------------------------------------------------------------------------"

export GRIBDIR=/home/ekman/ssd/guido/gfs/
export IMGDIR=/home/ekman/ssd/guido/gfs/
export MODEL_DATA_FOLDER=/home/ekman/ssd/guido/gfs/
export HOME_SCRIPTS=$(pwd)
export HOME_FOLDER=$(pwd)
export NCFTP_BOOKMARK="mid"
DATA_DOWNLOAD=true
DATA_PLOTTING=true
DATA_UPLOAD=true

#
export SHELL=$(type -p bash)
# We need to open many files at the same time
ulimit -Sn 8192
########################################### 

mkdir -p ${GRIBDIR}it
mkdir -p ${GRIBDIR}it
mkdir -p ${GRIBDIR}de
mkdir -p ${GRIBDIR}euratl
mkdir -p ${GRIBDIR}nh_polar

##### COMPUTE the date variables to determine the run
export MONTH=$(date -u +"%m")
export DAY=$(date -u +"%d")
export YEAR=$(date -u +"%Y")
export HOUR=$(date -u +"%H")

if [ $HOUR -ge 5 ] && [ $HOUR -lt 11 ]
then
    export RUN=00
elif [ $HOUR -ge 11 ] && [ $HOUR -lt 17 ]
then
    export RUN=06
elif [ $HOUR -ge 17 ]
then
    export RUN=12
elif [ $HOUR -ge 00 ] && [ $HOUR -lt 5 ]
then
    DAY=$(date -u -d'yesterday' +"%d")
    export RUN=18
else
    echo "Invalid hour!"
fi

echo "----------------------------------------------------------------------------------------------"
echo "gfs: run ${YEAR}${MONTH}${DAY}${RUN}"
echo "----------------------------------------------------------------------------------------------"

# Move to the data folder to do processing


cd ${GRIBDIR} || { echo 'Cannot change to DATA folder' ; exit 1; }


# SECTION 1 - DATA DOWNLOAD ############################################################

if [ "$DATA_DOWNLOAD" = true ]; then
    echo "----------------------------------------------------------------------------------------------"
    echo "gfs: Starting downloading of data - `date`"
    echo "----------------------------------------------------------------------------------------------"

    export SKIP_SAME_TIME=1
    export CDI_INVENTORY_MODE=time
    #clean out the old grib data
    rm ${GRIBDIR}grib_gfs*
    rm ${GRIBDIR}*.nc
    cp ${HOME_FOLDER}/*.py ${MODEL_DATA_FOLDER}

    python downloader.py \
    -d "${YEAR}${MONTH}${DAY}" \
    -r "${RUN}" \
    -v "PRMSL" "HGT" "TMP" "HGT" "TMP" "HGT" "TMP" "HGT" "TMP" "HGT" "SNOD" "CRAIN" "CSNOW" "PRATE" "APCP" "UGRD" "UGRD" "UGRD" "VGRD" "VGRD" "VGRD" "TMP" "TMP" "TMP"   \
    -l "mean sea level" "500 mb" "500 mb" "10 mb" "10 mb" "50 mb" "50 mb" "850 mb" "850 mb" "0C isotherm" "surface" "surface" "surface" "surface" "surface" "150 mb" "250 mb" "300 mb" "150 mb" "250 mb" "300 mb" "150 mb" "250 mb" "300 mb" \
    -o "${MODEL_DATA_FOLDER}"
    if [[ $? = 0 ]]; then
        echo "Downloaded files succesfully"
    else
        echo "Could not download data, exiting"
        exit 1
    fi

    # Delete empty files
    FILENAMES=$GRIBDIR"grib_gfs_"$YEAR$MONTH$DAY"_"$RUN"_*"
    find $FILENAMES -empty -type f -delete

    # We need sellonlatbox to shift the grid from 0,360 to -180, 180. Somehow it is
    # easier to do it now that afterwars in Python
    cdo -f nc copy -sellonlatbox,-180,180,-90,90 -mergetime \
                    $GRIBDIR"grib_gfs_"$YEAR$MONTH$DAY"_"$RUN"_*" \
                    $GRIBDIR"gfs_${YEAR}${MONTH}${DAY}${RUN}.nc"
    rm $GRIBDIR"grib_gfs_"$YEAR$MONTH$DAY"_"$RUN"_*"
fi

# SECTION 2 - DATA PLOTTING ############################################################

if [ "$DATA_PLOTTING" = true ]; then
    echo "----------------------------------------------------------------------------------------------"
    echo "gfs: Starting plotting of data - `date`"
    echo "----------------------------------------------------------------------------------------------"
    python --version
    cp ${HOME_FOLDER}/plotting/*.py ${MODEL_DATA_FOLDER}

    export QT_QPA_PLATFORM=offscreen # Needed to avoid errors when using Python without display

    scripts=("plot_gph_500_mslp.py" "plot_gph_t_50.py" "plot_gph_t_10.py" "plot_gph_t_850.py" \
             "plot_rain_acc.py" "plot_pv_250.py" "plot_rain_clouds.py" "plot_hsnow.py")

    projections=("euratl" "it" "de" "nh_polar")
    #projections=("euratl" "nh_polar")

    parallel -j 5 --delay 2 python ::: "${scripts[@]}" ::: "${projections[@]}"
    rm ${MODEL_DATA_FOLDER}*.py
fi


# SECTION 3 - IMAGES UPLOAD ############################################################
# Use ncftpbookmarks to add a new FTP server with credentials
if [ "$DATA_UPLOAD" = true ]; then
    echo "----------------------------------------------------------------------------------------------"
    echo "gfs: Starting FTP uploading - `date`"
    echo "----------------------------------------------------------------------------------------------"
    # Then upload the other pictures
    #
    images_output=("gph_500_mslp" "gph_t_50" "gph_t_850" "precip_acc" "gph_t_10" "pv_250" \
                    "hsnow" "precip_clouds")

    # suffix for naming
    projections_output=("euratl/" "it/" "de/" "nh_polar/")
    #projections_output=("euratl/" "nh_polar/")
    # remote folder on server
    projections_output_folder=("gfs_euratl" "gfs_it" "gfs_de" "gfs_nh_polar")
    #projections_output_folder=("gfs_euratl" "gfs_nh_polar")

    # Create a lisf of all the images to upload 
    upload_elements=()
    for i in "${!projections_output[@]}"; do
        for j in "${images_output[@]}"; do
                upload_elements+=("${projections_output_folder[$i]}/${j} ./${projections_output[$i]}${j}_*")
        done
    done

    for k in "${upload_elements[@]}"; do
        ncftpput -R -v -DD -m ${NCFTP_BOOKMARK} ${k}
    done
fi

# SECTION 4 - CLEANING ############################################################

#Remove images locally

echo "----------------------------------------------------------------------------------------------"
echo "gfs: Finished cleaning up - `date`"
echo "----------------------------------------------------------------------------------------------"

############################################################

cd -
