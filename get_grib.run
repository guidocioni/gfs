#!/bin/bash

# Cd into our working directory in case we're not into it already
cd "$(dirname "$0")";

echo "----------------------------------------------------------------------------------------------"
echo "gfs: Starting processing of GEFS model data - `date`"
echo "----------------------------------------------------------------------------------------------"

export GRIBDIR=/tmp/gfs/
export IMGDIR=/tmp/gfs/
export MODEL_DATA_FOLDER=/tmp/gfs/
export HOME_SCRIPTS=$(pwd)
export HOME_FOLDER=$(pwd)
export NCFTP_BOOKMARK="altervista"
DATA_DOWNLOAD=false
DATA_PLOTTING=false
DATA_UPLOAD=true

#
. ./functions_download_gefs.sh
export SHELL=$(type -p bash)
# We need to open many files at the same time
ulimit -Sn 8192
########################################### 

mkdir -p ${GRIBDIR}it
mkdir -p ${GRIBDIR}it
mkdir -p ${GRIBDIR}de
mkdir -p ${GRIBDIR}euratl
mkdir -p ${GRIBDIR}nh_polar

##### COMPUTE the date variables to determine the run
export MONTH=$(date -u +"%m")
export DATE=$(date -u +"%d")
export YEAR=$(date -u +"%Y")
export HOUR=$(date -u +"%H")

if [ $HOUR -ge 6 ] && [ $HOUR -lt 12 ]
then
    export RUN=00
elif [ $HOUR -ge 12 ] && [ $HOUR -lt 18 ]
then
    export RUN=06
elif [ $HOUR -ge 18 ]
then
    export RUN=12
elif [ $HOUR -ge 00 ] && [ $HOUR -lt 6 ]
then
    DATE=$(date -u -d'yesterday' +"%d")
    export RUN=18
else
    echo "Invalid hour!"
fi

# Move to the data folder to do processing


cd ${GRIBDIR} || { echo 'Cannot change to DATA folder' ; exit 1; }


# SECTION 1 - DATA DOWNLOAD ############################################################

if [ "$DATA_DOWNLOAD" = true ]; then
    echo "----------------------------------------------------------------------------------------------"
    echo "gfs: Starting downloading of data - `date`"
    echo "----------------------------------------------------------------------------------------------"

    #loop through forecast hours
    hours_download=$(seq -s " " 3 3 384)
    # hours_download=$(seq -s " " 3 3 12)
    export SKIP_SAME_TIME=1
    export CDI_INVENTORY_MODE=time
    #clean out the old grib data
    rm ${GRIBDIR}grib_gfs*
    rm ${GRIBDIR}*.nc

    parallel -j 20 download_gfs_data ::: $hours_download

    rm *.tmp

    # We need sellonlatbox to shift the grid from 0,360 to -180, 180. Somehow it is
    # easier to do it now that afterwars in Python
    cdo -f nc copy -sellonlatbox,-180,180,-90,90 -mergetime \
                    $GRIBDIR/"grib_gfs_"$YEAR$MONTH$DATE"_"$RUN"_*" \
                    $GRIBDIR/"gfs_${YEAR}${MONTH}${DATE}${RUN}.nc"
    rm *.grib
    # Remove all the non-netcdf files which are not necessary 
    #rm $GRIBDIR/*[!.nc]
fi

# SECTION 2 - DATA PLOTTING ############################################################

if [ "$DATA_PLOTTING" = true ]; then
    echo "----------------------------------------------------------------------------------------------"
    echo "gfs: Starting plotting of data - `date`"
    echo "----------------------------------------------------------------------------------------------"
    python --version
    cp ${HOME_FOLDER}/plotting/*.py ${MODEL_DATA_FOLDER}

    export QT_QPA_PLATFORM=offscreen # Needed to avoid errors when using Python without display

    scripts=("plot_gph_500_mslp.py" "plot_gph_t_50.py" "plot_gph_t_10.py" "plot_gph_t_850.py" "plot_rain_acc.py")

    projections=("euratl" "it" "de" "nh_polar")

    parallel -j 5 --delay 1 python ::: "${scripts[@]}" ::: "${projections[@]}"
    rm ${MODEL_DATA_FOLDER}*.py
fi


# SECTION 3 - IMAGES UPLOAD ############################################################
# Use ncftpbookmarks to add a new FTP server with credentials
if [ "$DATA_UPLOAD" = true ]; then
    echo "----------------------------------------------------------------------------------------------"
    echo "gfs: Starting FTP uploading - `date`"
    echo "----------------------------------------------------------------------------------------------"
    # Then upload the other pictures
    #
    images_output=("gph_500_mslp" "gph_t_50" "gph_t_850" "precip_acc" "gph_t_10")

    # suffix for naming
    projections_output=("euratl/" "it/" "de/" "nh_polar/")
    # remote folder on server
    projections_output_folder=("gfs_euratl" "gfs_it" "gfs_de" "gfs_nh_polar")

    # Create a lisf of all the images to upload 
    upload_elements=()
    for i in "${!projections_output[@]}"; do
        for j in "${images_output[@]}"; do
                upload_elements+=("${projections_output_folder[$i]}/${j} ./${projections_output[$i]}${j}_*")
        done
    done

    for k in "${upload_elements[@]}"; do
        ncftpput -R -v -DD -m ${NCFTP_BOOKMARK} ${k}
    done
fi

# SECTION 4 - CLEANING ############################################################

#Remove images locally

echo "----------------------------------------------------------------------------------------------"
echo "gfs: Finished cleaning up - `date`"
echo "----------------------------------------------------------------------------------------------"

############################################################

cd -
